{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e411f29f-b60e-4302-8178-068c20ea3d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "Copyright (C) 2019 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gcc --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70f700ee-0403-41fe-aa38-294384bb9fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check PyTorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d9111bd-ed09-481b-afe6-047c66813585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting configs/resnet/resnet18_8xb16_cifar10_alzheimer_axial_view.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile configs/resnet/resnet18_8xb16_cifar10_alzheimer_axial_view.py\n",
    "_base_ = [\n",
    "    '../_base_/models/resnet18.py',\n",
    "    '../_base_/schedules/imagenet_bs1024_adamw_conformer.py',\n",
    "    '../_base_/default_runtime.py'\n",
    "]\n",
    "\n",
    "model = dict(\n",
    "    type='ImageClassifier', \n",
    "    backbone=dict(\n",
    "        type='ResNet_CIFAR',\n",
    "        init_cfg = dict(\n",
    "            type='Pretrained', \n",
    "            #type='ResNet', \n",
    "            checkpoint='https://download.openmmlab.com/mmclassification/v0/resnet/resnet18_8xb32_in1k_20210831-fbbb1da6.pth', \n",
    "            prefix='backbone')\n",
    "    ),\n",
    "    head=dict(\n",
    "        num_classes=3,\n",
    "        topk = (1, ),\n",
    "    ))\n",
    "\n",
    "dataset_type = 'CustomDataset'\n",
    "data_preprocessor = dict(\n",
    "     mean=[124.508, 116.050, 106.438],\n",
    "     std=[58.577, 57.310, 57.437],\n",
    "     to_rgb=False)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),     # read image\n",
    "    dict(type='RandomResizedCrop', scale=100),\n",
    "    dict(type='RandomFlip', prob=0.5, direction='horizontal'),   # random horizontal flip\n",
    "    dict(type='PackInputs'),\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),     # read image\n",
    "    dict(type='ResizeEdge', scale=100),  # Scale the short side to 256\n",
    "    dict(type='CenterCrop', crop_size=100),\n",
    "    dict(type='PackInputs'),    \n",
    "]\n",
    "\n",
    "train_dataloader = dict(\n",
    "    batch_size=16,\n",
    "    num_workers=1,\n",
    "    dataset=dict(\n",
    "        type='CustomDataset',\n",
    "        data_prefix='data/YoriDataset_vgg/train',\n",
    "        classes='data/classes.txt',\n",
    "        # ann_file='data/train_ann.txt',\n",
    "        # with_label=True,\n",
    "        pipeline=train_pipeline\n",
    "    ),\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_dataloader = dict(\n",
    "    batch_size=32,\n",
    "    num_workers=1,\n",
    "    dataset=dict(\n",
    "        type='CustomDataset',\n",
    "        data_prefix='data/YoriDataset_vgg/validation',\n",
    "        classes='data/classes.txt',\n",
    "        # ann_file='data/val_ann.txt',\n",
    "        # with_label=True,\n",
    "        pipeline=test_pipeline\n",
    "    ),\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "test_dataloader = dict(\n",
    "    batch_size=32,\n",
    "    num_workers=1,\n",
    "    dataset=dict(\n",
    "        type='CustomDataset',\n",
    "        data_prefix='data/YoriDataset_vgg/test',\n",
    "        classes='data/classes.txt',\n",
    "        # ann_file='data/test_ann.txt',\n",
    "        # with_label=True,\n",
    "        pipeline=test_pipeline\n",
    "    ),    \n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_evaluator = dict(type='Accuracy', topk=(1, ))\n",
    "test_evaluator = val_evaluator \n",
    "\n",
    "optim_wrapper = dict(\n",
    "    optimizer=dict(\n",
    "        type='AdamW',\n",
    "        # for batch in each gpu is 128, 8 gpu\n",
    "        # lr = 5e-4 * 128 * 8 / 512 = 0.001\n",
    "        lr=5e-4 * 128 * 8 / 512,\n",
    "        weight_decay=0.05,\n",
    "        eps=1e-8,\n",
    "        betas=(0.9, 0.999)),\n",
    "    paramwise_cfg=dict(\n",
    "        norm_decay_mult=0.0,\n",
    "        bias_decay_mult=0.0,\n",
    "        custom_keys={\n",
    "            '.cls_token': dict(decay_mult=0.0),\n",
    "        }),\n",
    ")\n",
    "\n",
    "# learning policy\n",
    "param_scheduler = [\n",
    "    dict(\n",
    "        type='LinearLR',\n",
    "        start_factor=1e-3,\n",
    "        by_epoch=True,\n",
    "        begin=0,\n",
    "        end=5,\n",
    "        convert_to_iter_based=True),\n",
    "    dict(\n",
    "        type='CosineAnnealingLR',\n",
    "        T_max=295,\n",
    "        eta_min=1e-5,\n",
    "        by_epoch=True,\n",
    "        begin=5,\n",
    "        end=300)\n",
    "]\n",
    "\n",
    "train_cfg = dict(by_epoch=True, max_epochs=3, val_interval=1)\n",
    "val_cfg = dict()\n",
    "test_cfg = dict()\n",
    "\n",
    "auto_scale_lr = dict(base_batch_size=128)\n",
    "\n",
    "default_scope = 'mmpretrain'\n",
    "\n",
    "# configure default hooks\n",
    "default_hooks = dict(\n",
    "    # record the time of every iteration.\n",
    "    timer=dict(type='IterTimerHook'),\n",
    "\n",
    "    # print log every 100 iterations.\n",
    "    logger=dict(type='LoggerHook', interval=100),\n",
    "\n",
    "    # enable the parameter scheduler.\n",
    "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
    "\n",
    "    # save checkpoint per epoch.\n",
    "    checkpoint=dict(type='CheckpointHook', interval=1),\n",
    "\n",
    "    # set sampler seed in a distributed environment.\n",
    "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
    "\n",
    "    # validation results visualization, set True to enable it.\n",
    "    visualization=dict(type='VisualizationHook', enable=False),\n",
    ")\n",
    "\n",
    "env_cfg = dict(\n",
    "    # whether to enable cudnn benchmark\n",
    "    cudnn_benchmark=False,\n",
    "\n",
    "    # set multi-process parameters\n",
    "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
    "\n",
    "    # set distributed parameters\n",
    "    dist_cfg=dict(backend='nccl'),\n",
    ")\n",
    "\n",
    "# set visualizer\n",
    "vis_backends = [dict(type='LocalVisBackend')]  # use local HDD backend\n",
    "visualizer = dict(type='UniversalVisualizer', vis_backends=vis_backends, name='visualizer')\n",
    "\n",
    "# set log level\n",
    "log_level = 'INFO'\n",
    "\n",
    "# load from which checkpoint\n",
    "load_from = None\n",
    "\n",
    "# whether to resume training from the loaded checkpoint\n",
    "resume = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7386d1f-ff2d-4d61-8a99-84359d35d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/misc/print_config.py configs/resnet/resnet18_8xb16_cifar10_alzheimer_axial_view.py > final_config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af9b83db-fd61-4251-b785-362c7fe59e2a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/23 17:09:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "10/23 17:09:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::add_ encountered 16 time(s)\n",
      "10/23 17:09:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "data_preprocessor, head, head.fc, head.loss_module\n",
      "10/23 17:09:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::batch_norm encountered 53 time(s)\n",
      "10/23 17:09:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::adaptive_avg_pool2d encountered 1 time(s)\n",
      "\n",
      "N/A indicates a possibly missing statistic due to how the module was called. Missing values are still included in the parent's total.\n",
      "ImageClassifier(\n",
      "  #params: 25.56M, #flops: 4.11G, #acts: 11.11M\n",
      "  (data_preprocessor): ClsDataPreprocessor(#params: 0, #flops: N/A, #acts: N/A)\n",
      "  (backbone): ResNet(\n",
      "    #params: 23.51M, #flops: 4.11G, #acts: 11.11M\n",
      "    (conv1): Conv2d(\n",
      "      3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "      #params: 9.41K, #flops: 0.12G, #acts: 0.8M\n",
      "    )\n",
      "    (bn1): BatchNorm2d(\n",
      "      64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "      #params: 0.13K, #flops: 1.61M, #acts: 0\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): ResLayer(\n",
      "      #params: 0.22M, #flops: 0.68G, #acts: 4.42M\n",
      "      (0): Bottleneck(\n",
      "        #params: 75.01K, #flops: 0.24G, #acts: 2.01M\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 4.1K, #flops: 12.85M, #acts: 0.2M\n",
      "        )\n",
      "        (bn1): BatchNorm2d(\n",
      "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.13K, #flops: 0.4M, #acts: 0\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          #params: 36.86K, #flops: 0.12G, #acts: 0.2M\n",
      "        )\n",
      "        (bn2): BatchNorm2d(\n",
      "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.13K, #flops: 0.4M, #acts: 0\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 16.38K, #flops: 51.38M, #acts: 0.8M\n",
      "        )\n",
      "        (bn3): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.51K, #flops: 1.61M, #acts: 0\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          #params: 16.9K, #flops: 52.99M, #acts: 0.8M\n",
      "          (0): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            #params: 16.38K, #flops: 51.38M, #acts: 0.8M\n",
      "          )\n",
      "          (1): BatchNorm2d(\n",
      "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            #params: 0.51K, #flops: 1.61M, #acts: 0\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity(#params: 0, #flops: N/A, #acts: N/A)\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        #params: 70.4K, #flops: 0.22G, #acts: 1.2M\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 16.38K, #flops: 51.38M, #acts: 0.2M\n",
      "        )\n",
      "        (bn1): BatchNorm2d(\n",
      "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.13K, #flops: 0.4M, #acts: 0\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          #params: 36.86K, #flops: 0.12G, #acts: 0.2M\n",
      "        )\n",
      "        (bn2): BatchNorm2d(\n",
      "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.13K, #flops: 0.4M, #acts: 0\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 16.38K, #flops: 51.38M, #acts: 0.8M\n",
      "        )\n",
      "        (bn3): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.51K, #flops: 1.61M, #acts: 0\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop_path): Identity(#params: 0, #flops: N/A, #acts: N/A)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        #params: 70.4K, #flops: 0.22G, #acts: 1.2M\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 16.38K, #flops: 51.38M, #acts: 0.2M\n",
      "        )\n",
      "        (bn1): BatchNorm2d(\n",
      "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.13K, #flops: 0.4M, #acts: 0\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          #params: 36.86K, #flops: 0.12G, #acts: 0.2M\n",
      "        )\n",
      "        (bn2): BatchNorm2d(\n",
      "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.13K, #flops: 0.4M, #acts: 0\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 16.38K, #flops: 51.38M, #acts: 0.8M\n",
      "        )\n",
      "        (bn3): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.51K, #flops: 1.61M, #acts: 0\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop_path): Identity(#params: 0, #flops: N/A, #acts: N/A)\n",
      "      )\n",
      "    )\n",
      "    (layer2): ResLayer(\n",
      "      #params: 1.22M, #flops: 1.03G, #acts: 3.11M\n",
      "      (0): Bottleneck(\n",
      "        #params: 0.38M, #flops: 0.38G, #acts: 1.3M\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 32.77K, #flops: 0.1G, #acts: 0.4M\n",
      "        )\n",
      "        (bn1): BatchNorm2d(\n",
      "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.26K, #flops: 0.8M, #acts: 0\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "          #params: 0.15M, #flops: 0.12G, #acts: 0.1M\n",
      "        )\n",
      "        (bn2): BatchNorm2d(\n",
      "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.26K, #flops: 0.2M, #acts: 0\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 65.54K, #flops: 51.38M, #acts: 0.4M\n",
      "        )\n",
      "        (bn3): BatchNorm2d(\n",
      "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 1.02K, #flops: 0.8M, #acts: 0\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          #params: 0.13M, #flops: 0.1G, #acts: 0.4M\n",
      "          (0): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            #params: 0.13M, #flops: 0.1G, #acts: 0.4M\n",
      "          )\n",
      "          (1): BatchNorm2d(\n",
      "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            #params: 1.02K, #flops: 0.8M, #acts: 0\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity(#params: 0, #flops: N/A, #acts: N/A)\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        #params: 0.28M, #flops: 0.22G, #acts: 0.6M\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 65.54K, #flops: 51.38M, #acts: 0.1M\n",
      "        )\n",
      "        (bn1): BatchNorm2d(\n",
      "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.26K, #flops: 0.2M, #acts: 0\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          #params: 0.15M, #flops: 0.12G, #acts: 0.1M\n",
      "        )\n",
      "        (bn2): BatchNorm2d(\n",
      "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.26K, #flops: 0.2M, #acts: 0\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 65.54K, #flops: 51.38M, #acts: 0.4M\n",
      "        )\n",
      "        (bn3): BatchNorm2d(\n",
      "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 1.02K, #flops: 0.8M, #acts: 0\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop_path): Identity(#params: 0, #flops: N/A, #acts: N/A)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        #params: 0.28M, #flops: 0.22G, #acts: 0.6M\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 65.54K, #flops: 51.38M, #acts: 0.1M\n",
      "        )\n",
      "        (bn1): BatchNorm2d(\n",
      "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.26K, #flops: 0.2M, #acts: 0\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          #params: 0.15M, #flops: 0.12G, #acts: 0.1M\n",
      "        )\n",
      "        (bn2): BatchNorm2d(\n",
      "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.26K, #flops: 0.2M, #acts: 0\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 65.54K, #flops: 51.38M, #acts: 0.4M\n",
      "        )\n",
      "        (bn3): BatchNorm2d(\n",
      "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 1.02K, #flops: 0.8M, #acts: 0\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop_path): Identity(#params: 0, #flops: N/A, #acts: N/A)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        #params: 0.28M, #flops: 0.22G, #acts: 0.6M\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 65.54K, #flops: 51.38M, #acts: 0.1M\n",
      "        )\n",
      "        (bn1): BatchNorm2d(\n",
      "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.26K, #flops: 0.2M, #acts: 0\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          #params: 0.15M, #flops: 0.12G, #acts: 0.1M\n",
      "        )\n",
      "        (bn2): BatchNorm2d(\n",
      "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.26K, #flops: 0.2M, #acts: 0\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 65.54K, #flops: 51.38M, #acts: 0.4M\n",
      "        )\n",
      "        (bn3): BatchNorm2d(\n",
      "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 1.02K, #flops: 0.8M, #acts: 0\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop_path): Identity(#params: 0, #flops: N/A, #acts: N/A)\n",
      "      )\n",
      "    )\n",
      "    (layer3): ResLayer(\n",
      "      #params: 7.1M, #flops: 1.47G, #acts: 2.16M\n",
      "      (0): Bottleneck(\n",
      "        #params: 1.51M, #flops: 0.37G, #acts: 0.65M\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 0.13M, #flops: 0.1G, #acts: 0.2M\n",
      "        )\n",
      "        (bn1): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.51K, #flops: 0.4M, #acts: 0\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "          #params: 0.59M, #flops: 0.12G, #acts: 50.18K\n",
      "        )\n",
      "        (bn2): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.51K, #flops: 0.1M, #acts: 0\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 0.26M, #flops: 51.38M, #acts: 0.2M\n",
      "        )\n",
      "        (bn3): BatchNorm2d(\n",
      "          1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 2.05K, #flops: 0.4M, #acts: 0\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          #params: 0.53M, #flops: 0.1G, #acts: 0.2M\n",
      "          (0): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            #params: 0.52M, #flops: 0.1G, #acts: 0.2M\n",
      "          )\n",
      "          (1): BatchNorm2d(\n",
      "            1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            #params: 2.05K, #flops: 0.4M, #acts: 0\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity(#params: 0, #flops: N/A, #acts: N/A)\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        #params: 1.12M, #flops: 0.22G, #acts: 0.3M\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 0.26M, #flops: 51.38M, #acts: 50.18K\n",
      "        )\n",
      "        (bn1): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.51K, #flops: 0.1M, #acts: 0\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          #params: 0.59M, #flops: 0.12G, #acts: 50.18K\n",
      "        )\n",
      "        (bn2): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.51K, #flops: 0.1M, #acts: 0\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 0.26M, #flops: 51.38M, #acts: 0.2M\n",
      "        )\n",
      "        (bn3): BatchNorm2d(\n",
      "          1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 2.05K, #flops: 0.4M, #acts: 0\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop_path): Identity(#params: 0, #flops: N/A, #acts: N/A)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        #params: 1.12M, #flops: 0.22G, #acts: 0.3M\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 0.26M, #flops: 51.38M, #acts: 50.18K\n",
      "        )\n",
      "        (bn1): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.51K, #flops: 0.1M, #acts: 0\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          #params: 0.59M, #flops: 0.12G, #acts: 50.18K\n",
      "        )\n",
      "        (bn2): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.51K, #flops: 0.1M, #acts: 0\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 0.26M, #flops: 51.38M, #acts: 0.2M\n",
      "        )\n",
      "        (bn3): BatchNorm2d(\n",
      "          1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 2.05K, #flops: 0.4M, #acts: 0\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop_path): Identity(#params: 0, #flops: N/A, #acts: N/A)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        #params: 1.12M, #flops: 0.22G, #acts: 0.3M\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 0.26M, #flops: 51.38M, #acts: 50.18K\n",
      "        )\n",
      "        (bn1): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.51K, #flops: 0.1M, #acts: 0\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          #params: 0.59M, #flops: 0.12G, #acts: 50.18K\n",
      "        )\n",
      "        (bn2): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.51K, #flops: 0.1M, #acts: 0\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 0.26M, #flops: 51.38M, #acts: 0.2M\n",
      "        )\n",
      "        (bn3): BatchNorm2d(\n",
      "          1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 2.05K, #flops: 0.4M, #acts: 0\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop_path): Identity(#params: 0, #flops: N/A, #acts: N/A)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        #params: 1.12M, #flops: 0.22G, #acts: 0.3M\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 0.26M, #flops: 51.38M, #acts: 50.18K\n",
      "        )\n",
      "        (bn1): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.51K, #flops: 0.1M, #acts: 0\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          #params: 0.59M, #flops: 0.12G, #acts: 50.18K\n",
      "        )\n",
      "        (bn2): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.51K, #flops: 0.1M, #acts: 0\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 0.26M, #flops: 51.38M, #acts: 0.2M\n",
      "        )\n",
      "        (bn3): BatchNorm2d(\n",
      "          1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 2.05K, #flops: 0.4M, #acts: 0\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop_path): Identity(#params: 0, #flops: N/A, #acts: N/A)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        #params: 1.12M, #flops: 0.22G, #acts: 0.3M\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 0.26M, #flops: 51.38M, #acts: 50.18K\n",
      "        )\n",
      "        (bn1): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.51K, #flops: 0.1M, #acts: 0\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          #params: 0.59M, #flops: 0.12G, #acts: 50.18K\n",
      "        )\n",
      "        (bn2): BatchNorm2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 0.51K, #flops: 0.1M, #acts: 0\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 0.26M, #flops: 51.38M, #acts: 0.2M\n",
      "        )\n",
      "        (bn3): BatchNorm2d(\n",
      "          1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 2.05K, #flops: 0.4M, #acts: 0\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop_path): Identity(#params: 0, #flops: N/A, #acts: N/A)\n",
      "      )\n",
      "    )\n",
      "    (layer4): ResLayer(\n",
      "      #params: 14.96M, #flops: 0.81G, #acts: 0.63M\n",
      "      (0): Bottleneck(\n",
      "        #params: 6.04M, #flops: 0.37G, #acts: 0.33M\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 0.52M, #flops: 0.1G, #acts: 0.1M\n",
      "        )\n",
      "        (bn1): BatchNorm2d(\n",
      "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 1.02K, #flops: 0.2M, #acts: 0\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "          #params: 2.36M, #flops: 0.12G, #acts: 25.09K\n",
      "        )\n",
      "        (bn2): BatchNorm2d(\n",
      "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 1.02K, #flops: 50.18K, #acts: 0\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 1.05M, #flops: 51.38M, #acts: 0.1M\n",
      "        )\n",
      "        (bn3): BatchNorm2d(\n",
      "          2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 4.1K, #flops: 0.2M, #acts: 0\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          #params: 2.1M, #flops: 0.1G, #acts: 0.1M\n",
      "          (0): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            #params: 2.1M, #flops: 0.1G, #acts: 0.1M\n",
      "          )\n",
      "          (1): BatchNorm2d(\n",
      "            2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            #params: 4.1K, #flops: 0.2M, #acts: 0\n",
      "          )\n",
      "        )\n",
      "        (drop_path): Identity(#params: 0, #flops: N/A, #acts: N/A)\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        #params: 4.46M, #flops: 0.22G, #acts: 0.15M\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 1.05M, #flops: 51.38M, #acts: 25.09K\n",
      "        )\n",
      "        (bn1): BatchNorm2d(\n",
      "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 1.02K, #flops: 50.18K, #acts: 0\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          #params: 2.36M, #flops: 0.12G, #acts: 25.09K\n",
      "        )\n",
      "        (bn2): BatchNorm2d(\n",
      "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 1.02K, #flops: 50.18K, #acts: 0\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 1.05M, #flops: 51.38M, #acts: 0.1M\n",
      "        )\n",
      "        (bn3): BatchNorm2d(\n",
      "          2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 4.1K, #flops: 0.2M, #acts: 0\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop_path): Identity(#params: 0, #flops: N/A, #acts: N/A)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        #params: 4.46M, #flops: 0.22G, #acts: 0.15M\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 1.05M, #flops: 51.38M, #acts: 25.09K\n",
      "        )\n",
      "        (bn1): BatchNorm2d(\n",
      "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 1.02K, #flops: 50.18K, #acts: 0\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          #params: 2.36M, #flops: 0.12G, #acts: 25.09K\n",
      "        )\n",
      "        (bn2): BatchNorm2d(\n",
      "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 1.02K, #flops: 50.18K, #acts: 0\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          #params: 1.05M, #flops: 51.38M, #acts: 0.1M\n",
      "        )\n",
      "        (bn3): BatchNorm2d(\n",
      "          2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          #params: 4.1K, #flops: 0.2M, #acts: 0\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop_path): Identity(#params: 0, #flops: N/A, #acts: N/A)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (neck): GlobalAveragePooling(\n",
      "    #params: 0, #flops: 0.1M, #acts: 0\n",
      "    (gap): AdaptiveAvgPool2d(\n",
      "      output_size=(1, 1)\n",
      "      #params: 0, #flops: 0.1M, #acts: 0\n",
      "    )\n",
      "  )\n",
      "  (head): LinearClsHead(\n",
      "    #params: 2.05M, #flops: N/A, #acts: N/A\n",
      "    (loss_module): CrossEntropyLoss(#params: 0, #flops: N/A, #acts: N/A)\n",
      "    (fc): Linear(\n",
      "      in_features=2048, out_features=1000, bias=True\n",
      "      #params: 2.05M, #flops: N/A, #acts: N/A\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "+--------------------------+----------------------+-----------+--------------+\n",
      "|\u001b[1m \u001b[0m\u001b[1mmodule                  \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#parameters or shape\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#flops   \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#activations\u001b[0m\u001b[1m \u001b[0m|\n",
      "+--------------------------+----------------------+-----------+--------------+\n",
      "| model                    | 25.557M              | 4.109G    | 11.114M      |\n",
      "|  backbone                |  23.508M             |  4.109G   |  11.114M     |\n",
      "|   backbone.conv1         |   9.408K             |   0.118G  |   0.803M     |\n",
      "|    backbone.conv1.weight |    (64, 3, 7, 7)     |           |              |\n",
      "|   backbone.bn1           |   0.128K             |   1.606M  |   0          |\n",
      "|    backbone.bn1.weight   |    (64,)             |           |              |\n",
      "|    backbone.bn1.bias     |    (64,)             |           |              |\n",
      "|   backbone.layer1        |   0.216M             |   0.677G  |   4.415M     |\n",
      "|    backbone.layer1.0     |    75.008K           |    0.235G |    2.007M    |\n",
      "|    backbone.layer1.1     |    70.4K             |    0.221G |    1.204M    |\n",
      "|    backbone.layer1.2     |    70.4K             |    0.221G |    1.204M    |\n",
      "|   backbone.layer2        |   1.22M              |   1.034G  |   3.111M     |\n",
      "|    backbone.layer2.0     |    0.379M            |    0.375G |    1.305M    |\n",
      "|    backbone.layer2.1     |    0.28M             |    0.22G  |    0.602M    |\n",
      "|    backbone.layer2.2     |    0.28M             |    0.22G  |    0.602M    |\n",
      "|    backbone.layer2.3     |    0.28M             |    0.22G  |    0.602M    |\n",
      "|   backbone.layer3        |   7.098M             |   1.469G  |   2.158M     |\n",
      "|    backbone.layer3.0     |    1.512M            |    0.374G |    0.652M    |\n",
      "|    backbone.layer3.1     |    1.117M            |    0.219G |    0.301M    |\n",
      "|    backbone.layer3.2     |    1.117M            |    0.219G |    0.301M    |\n",
      "|    backbone.layer3.3     |    1.117M            |    0.219G |    0.301M    |\n",
      "|    backbone.layer3.4     |    1.117M            |    0.219G |    0.301M    |\n",
      "|    backbone.layer3.5     |    1.117M            |    0.219G |    0.301M    |\n",
      "|   backbone.layer4        |   14.965M            |   0.81G   |   0.627M     |\n",
      "|    backbone.layer4.0     |    6.04M             |    0.373G |    0.326M    |\n",
      "|    backbone.layer4.1     |    4.463M            |    0.219G |    0.151M    |\n",
      "|    backbone.layer4.2     |    4.463M            |    0.219G |    0.151M    |\n",
      "|  head.fc                 |  2.049M              |           |              |\n",
      "|   head.fc.weight         |   (1000, 2048)       |           |              |\n",
      "|   head.fc.bias           |   (1000,)            |           |              |\n",
      "|  neck.gap                |                      |  0.1M     |  0           |\n",
      "+--------------------------+----------------------+-----------+--------------+\n",
      "\n",
      "==============================\n",
      "Input shape: (3, 224, 224)\n",
      "Flops: 4.109G\n",
      "Params: 25.557M\n",
      "Activation: 11.114M\n",
      "==============================\n",
      "!!!Only the backbone network is counted in FLOPs analysis.\n",
      "!!!Please be cautious if you use the results in papers. You may need to check if all ops are supported and verify that the flops computation is correct.\n"
     ]
    }
   ],
   "source": [
    "!python tools/analysis_tools/get_flops.py configs/resnet/resnet50_8xb32_in1k.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3097b65-d46e-4057-ba7b-bc27b2891991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac2cff-bcd7-4b3d-870e-3a3c313be038",
   "metadata": {},
   "source": [
    "# Axial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bf426a7-47aa-4504-bda5-712268ca6e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      "test\n",
      "train\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "paths = {'data/YoriDataset_vgg/train',\n",
    "        'data/YoriDataset_vgg/validation',\n",
    "        'data/YoriDataset_vgg/test'}\n",
    "\n",
    "for path in paths:\n",
    "    dtset = path.split('/')[2]\n",
    "    print(dtset)\n",
    "    img_dict = []\n",
    "    for i in os.listdir(path):\n",
    "        classname = i\n",
    "        class_path = os.path.join(path, classname)\n",
    "        for j in os.listdir(class_path):\n",
    "            img_name = classname + '/' + j\n",
    "            idx = 0 if i=='AD' else (1 if i=='MCI' else 2)\n",
    "            img_dict.append(img_name + ' ' + str(idx)+'\\n')\n",
    "            \n",
    "    if dtset == 'train':\n",
    "        with open('data/train_ann.txt', \"w\") as file:\n",
    "            for img in img_dict:\n",
    "                file.write(img)\n",
    "\n",
    "    elif dtset == 'validation':\n",
    "        with open('data/val_ann.txt', \"w\") as file:\n",
    "            for img in img_dict:\n",
    "                file.write(img)\n",
    "\n",
    "    else:\n",
    "        with open('data/test_ann.txt', \"w\") as file:\n",
    "            for img in img_dict:\n",
    "                file.write(img)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcff82d-670e-4213-bd4b-a5a8bb667a8e",
   "metadata": {},
   "source": [
    "# Coronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79e1f730-8b1a-4795-ac82-413f8ebfc314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "train\n",
      "validation\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "paths = {'data/Coronal/train',\n",
    "        'data/Coronal/validation',\n",
    "        'data/Coronal/test'}\n",
    "\n",
    "for path in paths:\n",
    "    dtset = path.split('/')[2]\n",
    "    print(dtset)\n",
    "    img_dict = []\n",
    "    for i in os.listdir(path):\n",
    "        classname = i\n",
    "        class_path = os.path.join(path, classname)\n",
    "        for j in os.listdir(class_path):\n",
    "            img_name = classname + '/' + j\n",
    "            idx = 0 if i=='AD' else (1 if i=='MCI' else 2)\n",
    "            img_dict.append(img_name + ' ' + str(idx)+'\\n')\n",
    "            \n",
    "    if dtset == 'train':\n",
    "        with open('data/Coronal/train_ann.txt', \"w\") as file:\n",
    "            for img in img_dict:\n",
    "                file.write(img)\n",
    "\n",
    "    elif dtset == 'validation':\n",
    "        with open('data/Coronal/val_ann.txt', \"w\") as file:\n",
    "            for img in img_dict:\n",
    "                file.write(img)\n",
    "\n",
    "    else:\n",
    "        with open('data/Coronal/test_ann.txt', \"w\") as file:\n",
    "            for img in img_dict:\n",
    "                file.write(img)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e93c40-efdf-49a1-b3fc-d48c754d6c3a",
   "metadata": {},
   "source": [
    "# Sagittal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "047e302c-4b49-4ab3-b6bc-029d9a3440b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      "test\n",
      "train\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "paths = {'data/Sagittal/train',\n",
    "        'data/Sagittal/validation',\n",
    "        'data/Sagittal/test'}\n",
    "\n",
    "for path in paths:\n",
    "    dtset = path.split('/')[2]\n",
    "    print(dtset)\n",
    "    img_dict = []\n",
    "    for i in os.listdir(path):\n",
    "        classname = i\n",
    "        class_path = os.path.join(path, classname)\n",
    "        for j in os.listdir(class_path):\n",
    "            img_name = classname + '/' + j\n",
    "            idx = 0 if i=='AD' else (1 if i=='MCI' else 2)\n",
    "            img_dict.append(img_name + ' ' + str(idx)+'\\n')\n",
    "            \n",
    "    if dtset == 'train':\n",
    "        with open('data/Sagittal/train_ann.txt', \"w\") as file:\n",
    "            for img in img_dict:\n",
    "                file.write(img)\n",
    "\n",
    "    elif dtset == 'validation':\n",
    "        with open('data/Sagittal/val_ann.txt', \"w\") as file:\n",
    "            for img in img_dict:\n",
    "                file.write(img)\n",
    "\n",
    "    else:\n",
    "        with open('data/Sagittal/test_ann.txt', \"w\") as file:\n",
    "            for img in img_dict:\n",
    "                file.write(img)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4529fb54-61fe-4395-a6d6-3bf715235bfb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'pred_scores': array([0.00106361, 0.00111506, 0.00095674, 0.00110361, 0.0010001 ,\n",
       "        0.0010419 , 0.00108305, 0.00095124, 0.00099276, 0.00099574,\n",
       "        0.00106059, 0.00102096, 0.00097904, 0.00110516, 0.00100241,\n",
       "        0.00096707, 0.00102797, 0.00104385, 0.0009454 , 0.00094476,\n",
       "        0.00107332, 0.00103814, 0.00100157, 0.00096211, 0.00092681,\n",
       "        0.00102684, 0.0009478 , 0.00101916, 0.00093637, 0.00098361,\n",
       "        0.0009844 , 0.00100575, 0.00091672, 0.00091535, 0.00094649,\n",
       "        0.0010397 , 0.00103915, 0.00097424, 0.00101287, 0.00096082,\n",
       "        0.00104501, 0.00103693, 0.00103628, 0.00098932, 0.00103774,\n",
       "        0.00099746, 0.00103596, 0.0010846 , 0.00098667, 0.00096192,\n",
       "        0.00096402, 0.00098036, 0.00102053, 0.00099826, 0.00107305,\n",
       "        0.0009114 , 0.00102417, 0.00103949, 0.00099881, 0.00100142,\n",
       "        0.00106068, 0.00101036, 0.00101346, 0.00101915, 0.00101727,\n",
       "        0.00098596, 0.00091057, 0.00104703, 0.00095481, 0.00101613,\n",
       "        0.00105949, 0.00097697, 0.00097473, 0.00106961, 0.0009721 ,\n",
       "        0.00092201, 0.00104137, 0.00104756, 0.00100211, 0.00100761,\n",
       "        0.00094787, 0.0010557 , 0.00097193, 0.0010528 , 0.00092844,\n",
       "        0.001045  , 0.00103692, 0.00109656, 0.00098663, 0.00107286,\n",
       "        0.00089236, 0.00106063, 0.00094485, 0.00106492, 0.00092315,\n",
       "        0.00096897, 0.00096287, 0.00109136, 0.0010692 , 0.0010644 ,\n",
       "        0.00099554, 0.00102294, 0.00103791, 0.00096202, 0.00099426,\n",
       "        0.00097526, 0.00097353, 0.00097602, 0.00098384, 0.0009761 ,\n",
       "        0.0010067 , 0.00101687, 0.00105315, 0.00093089, 0.00105318,\n",
       "        0.00097118, 0.00094225, 0.00105963, 0.00094475, 0.00098673,\n",
       "        0.0010093 , 0.00101951, 0.00101342, 0.00096022, 0.00096153,\n",
       "        0.0009744 , 0.00105115, 0.00102751, 0.00098167, 0.00099579,\n",
       "        0.00097894, 0.00095569, 0.00108879, 0.00096306, 0.00096709,\n",
       "        0.0009347 , 0.00106674, 0.00107716, 0.00100799, 0.00091905,\n",
       "        0.00095393, 0.00098628, 0.00095874, 0.00106376, 0.00097261,\n",
       "        0.00104851, 0.00103666, 0.00101958, 0.00103745, 0.00097387,\n",
       "        0.00096593, 0.00095817, 0.00096981, 0.00109045, 0.00094657,\n",
       "        0.00103487, 0.00105095, 0.00102213, 0.00097798, 0.00098068,\n",
       "        0.00091823, 0.00096826, 0.00101496, 0.00099636, 0.00106256,\n",
       "        0.0010278 , 0.00098466, 0.00099467, 0.00100866, 0.00097565,\n",
       "        0.00102964, 0.00101964, 0.00098388, 0.00105627, 0.00090872,\n",
       "        0.00095624, 0.00102464, 0.00101913, 0.00097719, 0.00102484,\n",
       "        0.00099806, 0.00099065, 0.00100464, 0.00093121, 0.00100296,\n",
       "        0.00093118, 0.00101869, 0.00105285, 0.00102999, 0.00097234,\n",
       "        0.00102812, 0.00111365, 0.00092981, 0.00091795, 0.00105388,\n",
       "        0.00100458, 0.00105247, 0.00102768, 0.00102971, 0.00095035,\n",
       "        0.00100405, 0.00098961, 0.00095673, 0.00091827, 0.00101764,\n",
       "        0.00095463, 0.00101003, 0.00096417, 0.00095914, 0.00097527,\n",
       "        0.00112399, 0.00103588, 0.00097747, 0.00097671, 0.00096546,\n",
       "        0.00097248, 0.00102959, 0.00091966, 0.00098619, 0.00101784,\n",
       "        0.00103234, 0.00097385, 0.00101103, 0.00091769, 0.00101118,\n",
       "        0.00100787, 0.00103678, 0.00102448, 0.00106509, 0.001087  ,\n",
       "        0.00093736, 0.00098622, 0.00095438, 0.00105904, 0.00091957,\n",
       "        0.00107732, 0.00094058, 0.00102514, 0.00110488, 0.00095857,\n",
       "        0.0009541 , 0.00105442, 0.00091216, 0.00098443, 0.00110129,\n",
       "        0.00111969, 0.00096357, 0.00100518, 0.00092334, 0.00104298,\n",
       "        0.0009343 , 0.00097611, 0.00100878, 0.00093932, 0.00089121,\n",
       "        0.0010343 , 0.0009638 , 0.00091122, 0.00097152, 0.00107156,\n",
       "        0.00095305, 0.00104388, 0.00097411, 0.00105545, 0.00101574,\n",
       "        0.00108911, 0.00098135, 0.00104891, 0.00103243, 0.00099538,\n",
       "        0.00098647, 0.00096579, 0.00100822, 0.00098385, 0.0010344 ,\n",
       "        0.00099434, 0.00107351, 0.00097941, 0.00099915, 0.0009998 ,\n",
       "        0.0009322 , 0.00099099, 0.00102308, 0.00094106, 0.00101765,\n",
       "        0.00097994, 0.00097157, 0.00102894, 0.00096295, 0.00100585,\n",
       "        0.00100878, 0.00107496, 0.00097693, 0.00101773, 0.00102997,\n",
       "        0.00094197, 0.00100145, 0.0009141 , 0.00100457, 0.00095141,\n",
       "        0.0009595 , 0.00108908, 0.0009182 , 0.00096766, 0.00100412,\n",
       "        0.00105058, 0.00105973, 0.00104136, 0.00103819, 0.00091078,\n",
       "        0.00095674, 0.00107227, 0.00099821, 0.00097802, 0.0010011 ,\n",
       "        0.00106183, 0.0010395 , 0.00099723, 0.000994  , 0.00099388,\n",
       "        0.00095717, 0.00093212, 0.00101034, 0.00100639, 0.00103122,\n",
       "        0.00090688, 0.00099023, 0.00101454, 0.0009597 , 0.00098926,\n",
       "        0.00095213, 0.00101715, 0.00100623, 0.00100665, 0.00101344,\n",
       "        0.00100625, 0.0010211 , 0.00106157, 0.00091448, 0.0009979 ,\n",
       "        0.00103823, 0.00099876, 0.00106563, 0.00106409, 0.00100632,\n",
       "        0.00095473, 0.00100735, 0.00094884, 0.00090933, 0.0009907 ,\n",
       "        0.00100265, 0.00103648, 0.0009579 , 0.00104962, 0.00097296,\n",
       "        0.00105807, 0.00095198, 0.00098632, 0.00097771, 0.00101952,\n",
       "        0.00094852, 0.0010068 , 0.00097296, 0.00100076, 0.00098739,\n",
       "        0.00100815, 0.00100711, 0.00095879, 0.00103423, 0.00103824,\n",
       "        0.00099823, 0.00099453, 0.00096847, 0.00105167, 0.00102346,\n",
       "        0.00105314, 0.00097519, 0.00099847, 0.0009945 , 0.00106679,\n",
       "        0.00106399, 0.00094023, 0.00099963, 0.00104273, 0.00096847,\n",
       "        0.00097701, 0.00097819, 0.00105582, 0.00099876, 0.00098751,\n",
       "        0.00101099, 0.00099475, 0.00104241, 0.00103973, 0.00103096,\n",
       "        0.00106547, 0.00102048, 0.00097387, 0.00100058, 0.00107041,\n",
       "        0.00093676, 0.00106125, 0.00103106, 0.00099098, 0.00096697,\n",
       "        0.00093834, 0.00095388, 0.00100965, 0.00105387, 0.00101731,\n",
       "        0.00105327, 0.00102899, 0.00093335, 0.00101371, 0.00103255,\n",
       "        0.00098696, 0.0009827 , 0.0010851 , 0.00101413, 0.00098586,\n",
       "        0.00100238, 0.00093491, 0.00110185, 0.00099733, 0.00100873,\n",
       "        0.0009547 , 0.00099806, 0.00105653, 0.00090072, 0.00098055,\n",
       "        0.0010157 , 0.00101623, 0.00096789, 0.00099901, 0.00101106,\n",
       "        0.00092936, 0.00097674, 0.00094746, 0.0010194 , 0.00102763,\n",
       "        0.00097693, 0.00103222, 0.00100307, 0.00101508, 0.00101138,\n",
       "        0.00103807, 0.00100561, 0.00099059, 0.00098062, 0.00102952,\n",
       "        0.00100272, 0.00102481, 0.00100974, 0.00094196, 0.00099309,\n",
       "        0.00102505, 0.00096183, 0.00092769, 0.00095342, 0.00095151,\n",
       "        0.00098408, 0.00095503, 0.00097224, 0.0009894 , 0.00104702,\n",
       "        0.00096755, 0.00099911, 0.00097242, 0.00104821, 0.00099021,\n",
       "        0.00102974, 0.00099453, 0.0009712 , 0.00089985, 0.00099004,\n",
       "        0.00103052, 0.00104723, 0.00098279, 0.00097635, 0.00094743,\n",
       "        0.00103373, 0.00104866, 0.00099098, 0.0011044 , 0.00095625,\n",
       "        0.0010018 , 0.00100453, 0.00101279, 0.00099938, 0.00096861,\n",
       "        0.00103752, 0.00099838, 0.00105127, 0.00100559, 0.00100238,\n",
       "        0.00098634, 0.00100639, 0.00098806, 0.00097172, 0.00107936,\n",
       "        0.0010895 , 0.00095932, 0.00103421, 0.00104068, 0.0010035 ,\n",
       "        0.00097977, 0.00105883, 0.00099571, 0.00101327, 0.00098455,\n",
       "        0.00095228, 0.0009676 , 0.00102254, 0.0010149 , 0.00094865,\n",
       "        0.00094281, 0.00097781, 0.00098583, 0.00102211, 0.00094693,\n",
       "        0.00101993, 0.00094792, 0.00102016, 0.00101707, 0.00102355,\n",
       "        0.00107841, 0.00093329, 0.00104888, 0.0009411 , 0.00094165,\n",
       "        0.00098379, 0.00096983, 0.00106586, 0.00097743, 0.0009908 ,\n",
       "        0.00104446, 0.00101954, 0.00098782, 0.00096428, 0.00103127,\n",
       "        0.0009614 , 0.00101914, 0.00101479, 0.00098624, 0.00097864,\n",
       "        0.00108451, 0.00097554, 0.001077  , 0.00096667, 0.00103325,\n",
       "        0.0009719 , 0.00103375, 0.00100421, 0.00093378, 0.00104088,\n",
       "        0.00101566, 0.00095462, 0.00099851, 0.0009741 , 0.00093535,\n",
       "        0.0009632 , 0.00094972, 0.00103782, 0.00093255, 0.0008878 ,\n",
       "        0.00102566, 0.00088029, 0.00094705, 0.00099544, 0.0009534 ,\n",
       "        0.00107564, 0.00101871, 0.00105262, 0.00099232, 0.00095256,\n",
       "        0.00105602, 0.00098966, 0.00094519, 0.00097905, 0.00096499,\n",
       "        0.00095641, 0.00101538, 0.00101029, 0.00099428, 0.00108974,\n",
       "        0.00096479, 0.00101355, 0.00099003, 0.00099274, 0.00098916,\n",
       "        0.00093818, 0.00105288, 0.0009406 , 0.00097524, 0.00108338,\n",
       "        0.00092978, 0.00095353, 0.00099271, 0.00104309, 0.00101122,\n",
       "        0.00104454, 0.00096768, 0.00089977, 0.0010143 , 0.0010426 ,\n",
       "        0.00097707, 0.00094499, 0.00099209, 0.00093202, 0.00097022,\n",
       "        0.00106384, 0.00098545, 0.00103607, 0.00106644, 0.00100781,\n",
       "        0.00092067, 0.00101067, 0.00096193, 0.0009979 , 0.00104135,\n",
       "        0.00104734, 0.00101059, 0.00103552, 0.00107089, 0.00097862,\n",
       "        0.0010729 , 0.00091824, 0.00095913, 0.0010672 , 0.00087696,\n",
       "        0.0009204 , 0.0009342 , 0.00104199, 0.00090791, 0.0009747 ,\n",
       "        0.00094467, 0.000998  , 0.00100027, 0.00101321, 0.00102525,\n",
       "        0.00093825, 0.00091093, 0.00096356, 0.00104133, 0.00099883,\n",
       "        0.00094765, 0.00094042, 0.00092187, 0.00107804, 0.00102352,\n",
       "        0.00102661, 0.00099699, 0.00103963, 0.00094002, 0.00106101,\n",
       "        0.00092942, 0.00102567, 0.00101843, 0.00098899, 0.00108731,\n",
       "        0.00098059, 0.00097841, 0.00092959, 0.00098552, 0.00093623,\n",
       "        0.00102873, 0.00098418, 0.00105188, 0.0010384 , 0.00104661,\n",
       "        0.00096206, 0.00094262, 0.00094279, 0.00097376, 0.00104662,\n",
       "        0.00094858, 0.00103265, 0.00104094, 0.00100701, 0.0009771 ,\n",
       "        0.00097971, 0.00102243, 0.0010556 , 0.00102213, 0.00096098,\n",
       "        0.00109913, 0.00100493, 0.00096864, 0.0010434 , 0.00098355,\n",
       "        0.00101774, 0.00099682, 0.00098229, 0.00099877, 0.00093873,\n",
       "        0.00090513, 0.00104686, 0.00096265, 0.00098251, 0.00104515,\n",
       "        0.00097267, 0.0010225 , 0.00100635, 0.00099048, 0.00097125,\n",
       "        0.0009566 , 0.0010586 , 0.0010072 , 0.00107539, 0.00101411,\n",
       "        0.00103767, 0.00099259, 0.00097259, 0.00109654, 0.00098723,\n",
       "        0.00105711, 0.00105079, 0.00100258, 0.0009592 , 0.00097687,\n",
       "        0.00102184, 0.00105764, 0.00104626, 0.00101539, 0.00100837,\n",
       "        0.00097419, 0.00104054, 0.00098761, 0.00092852, 0.00098472,\n",
       "        0.0009945 , 0.00099195, 0.00100575, 0.00094802, 0.00109222,\n",
       "        0.00100132, 0.0009943 , 0.00108404, 0.00104566, 0.00102213,\n",
       "        0.00095661, 0.00094079, 0.00104633, 0.00106294, 0.0010313 ,\n",
       "        0.00093495, 0.000931  , 0.00107706, 0.00101739, 0.00095663,\n",
       "        0.00098452, 0.00102618, 0.00101819, 0.0010443 , 0.00094189,\n",
       "        0.00097142, 0.00099109, 0.00101793, 0.00102667, 0.0010761 ,\n",
       "        0.00102972, 0.00100958, 0.00098588, 0.00108463, 0.00107575,\n",
       "        0.00099751, 0.0010062 , 0.00104354, 0.00100594, 0.00095784,\n",
       "        0.00100877, 0.00094036, 0.0010227 , 0.00103774, 0.00105023,\n",
       "        0.00091198, 0.00100112, 0.00103232, 0.00093851, 0.00100722,\n",
       "        0.00101096, 0.00097935, 0.00100459, 0.0009665 , 0.00100481,\n",
       "        0.00101301, 0.000961  , 0.00095503, 0.0010635 , 0.00093939,\n",
       "        0.00105137, 0.00093114, 0.00102135, 0.0010651 , 0.00105268,\n",
       "        0.00100678, 0.00104115, 0.00099943, 0.0009797 , 0.0009202 ,\n",
       "        0.00102882, 0.00100966, 0.00109737, 0.00103006, 0.00098092,\n",
       "        0.00099756, 0.00104552, 0.0009626 , 0.00112019, 0.00102178,\n",
       "        0.00093243, 0.00101816, 0.00100794, 0.00102975, 0.00101011,\n",
       "        0.00095446, 0.00097765, 0.00095914, 0.00091011, 0.00106296,\n",
       "        0.00103975, 0.00104636, 0.00095632, 0.00103083, 0.00096078,\n",
       "        0.00094763, 0.00096534, 0.00091413, 0.00104844, 0.00094663,\n",
       "        0.00100804, 0.00101339, 0.0009854 , 0.00094448, 0.00093137,\n",
       "        0.0009981 , 0.0009793 , 0.00101554, 0.00102711, 0.00102752,\n",
       "        0.00098437, 0.00101097, 0.00101233, 0.00092259, 0.00100454,\n",
       "        0.00102473, 0.00094453, 0.0010757 , 0.00100529, 0.00103374,\n",
       "        0.00101323, 0.00095654, 0.00097791, 0.00101268, 0.0009881 ,\n",
       "        0.00101648, 0.00109057, 0.00109752, 0.00106525, 0.00102856,\n",
       "        0.00106047, 0.00110658, 0.0009669 , 0.00101999, 0.00100123,\n",
       "        0.00096871, 0.00097805, 0.00095079, 0.00099316, 0.00097419,\n",
       "        0.00096799, 0.0009637 , 0.00089152, 0.00097528, 0.00091698,\n",
       "        0.00100728, 0.0010193 , 0.00101976, 0.00105136, 0.00100429,\n",
       "        0.00102702, 0.00094809, 0.00099955, 0.0009923 , 0.00099517,\n",
       "        0.00099973, 0.00102653, 0.00097844, 0.00093549, 0.00095455,\n",
       "        0.00099456, 0.00097256, 0.00098883, 0.00095573, 0.00104938,\n",
       "        0.00099907, 0.00101563, 0.00093821, 0.00096913, 0.00100885,\n",
       "        0.0010167 , 0.00103799, 0.00096992, 0.00103785, 0.00100455,\n",
       "        0.00093343, 0.00107676, 0.00095213, 0.0009767 , 0.00106773,\n",
       "        0.00102429, 0.00108105, 0.00094148, 0.00112113, 0.00097901,\n",
       "        0.00099179, 0.000941  , 0.00103927, 0.00099848, 0.00101227,\n",
       "        0.00097562, 0.00099905, 0.00096808, 0.00098794, 0.00106894,\n",
       "        0.00097791, 0.00100975, 0.00097956, 0.00103869, 0.0009971 ,\n",
       "        0.00103263, 0.00106133, 0.00099076, 0.00104855, 0.00103647,\n",
       "        0.00102968, 0.00107664, 0.00098893, 0.0009752 , 0.00102691,\n",
       "        0.00088998, 0.00096527, 0.00100462, 0.00097477, 0.00104208,\n",
       "        0.0010389 , 0.00093407, 0.00103845, 0.0010187 , 0.0010092 ,\n",
       "        0.00096739, 0.0009529 , 0.00094736, 0.00100724, 0.00104305,\n",
       "        0.00103776, 0.00098404, 0.00099043, 0.00100854, 0.0010544 ,\n",
       "        0.00095607, 0.0010228 , 0.00103148, 0.00094941, 0.00096575,\n",
       "        0.00103557, 0.00105525, 0.00092859, 0.00100951, 0.00097073,\n",
       "        0.001067  , 0.00095118, 0.00100966, 0.00098919, 0.0010531 ,\n",
       "        0.00107189, 0.00097668, 0.00096765, 0.00111248, 0.00099909,\n",
       "        0.00096824, 0.00102796, 0.00098988, 0.00097531, 0.00096495,\n",
       "        0.00092851, 0.00101496, 0.00105186, 0.00102378, 0.00111134,\n",
       "        0.0010041 , 0.00103813, 0.00097633, 0.00096321, 0.00093199,\n",
       "        0.0009646 , 0.00105634, 0.00094703, 0.00099637, 0.00099982],\n",
       "       dtype=float32),\n",
       " 'pred_label': 210,\n",
       " 'pred_score': 0.0011239880695939064,\n",
       " 'pred_class': 'German short-haired pointer'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmpretrain import get_model, inference_model\n",
    "\n",
    "model = get_model('resnet18_8xb32_in1k', device='cpu')  # or device='cuda:0'\n",
    "inference_model(model, 'demo/demo.JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b199108d-e8df-4cd6-909d-8bf8dfc9c49e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: work_dirs/alzheimer/axial/vgg16/latest1.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for backbone.conv1.weight: copying a param with shape torch.Size([64, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 3, 3, 3]).\n",
      "size mismatch for head.fc.weight: copying a param with shape torch.Size([2, 512]) from checkpoint, the shape in current model is torch.Size([3, 512]).\n",
      "size mismatch for head.fc.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n",
      "backbone ResNet_CIFAR(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): ResLayer(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer2): ResLayer(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer3): ResLayer(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer4): ResLayer(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmclassification/v0/resnet/resnet18_8xb32_in1k_20210831-fbbb1da6.pth', 'prefix': 'backbone'}\n",
      "backbone.conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "backbone.bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.relu ReLU(inplace=True)\n",
      "backbone.layer1 ResLayer(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (drop_path): Identity()\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (drop_path): Identity()\n",
      "  )\n",
      ")\n",
      "backbone.layer1.0 BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (drop_path): Identity()\n",
      ")\n",
      "backbone.layer1.0.conv1 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "backbone.layer1.0.bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer1.0.conv2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "backbone.layer1.0.bn2 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer1.0.relu ReLU(inplace=True)\n",
      "backbone.layer1.0.drop_path Identity()\n",
      "backbone.layer1.1 BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (drop_path): Identity()\n",
      ")\n",
      "backbone.layer1.1.conv1 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "backbone.layer1.1.bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer1.1.conv2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "backbone.layer1.1.bn2 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer1.1.relu ReLU(inplace=True)\n",
      "backbone.layer1.1.drop_path Identity()\n",
      "backbone.layer2 ResLayer(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (drop_path): Identity()\n",
      "  )\n",
      ")\n",
      "backbone.layer2.0 BasicBlock(\n",
      "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      ")\n",
      "backbone.layer2.0.conv1 Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "backbone.layer2.0.bn1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer2.0.conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "backbone.layer2.0.bn2 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer2.0.relu ReLU(inplace=True)\n",
      "backbone.layer2.0.downsample Sequential(\n",
      "  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "backbone.layer2.0.downsample.0 Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "backbone.layer2.0.downsample.1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer2.0.drop_path Identity()\n",
      "backbone.layer2.1 BasicBlock(\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (drop_path): Identity()\n",
      ")\n",
      "backbone.layer2.1.conv1 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "backbone.layer2.1.bn1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer2.1.conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "backbone.layer2.1.bn2 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer2.1.relu ReLU(inplace=True)\n",
      "backbone.layer2.1.drop_path Identity()\n",
      "backbone.layer3 ResLayer(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (drop_path): Identity()\n",
      "  )\n",
      ")\n",
      "backbone.layer3.0 BasicBlock(\n",
      "  (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      ")\n",
      "backbone.layer3.0.conv1 Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "backbone.layer3.0.bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer3.0.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "backbone.layer3.0.bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer3.0.relu ReLU(inplace=True)\n",
      "backbone.layer3.0.downsample Sequential(\n",
      "  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "backbone.layer3.0.downsample.0 Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "backbone.layer3.0.downsample.1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer3.0.drop_path Identity()\n",
      "backbone.layer3.1 BasicBlock(\n",
      "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (drop_path): Identity()\n",
      ")\n",
      "backbone.layer3.1.conv1 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "backbone.layer3.1.bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer3.1.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "backbone.layer3.1.bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer3.1.relu ReLU(inplace=True)\n",
      "backbone.layer3.1.drop_path Identity()\n",
      "backbone.layer4 ResLayer(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (drop_path): Identity()\n",
      "  )\n",
      ")\n",
      "backbone.layer4.0 BasicBlock(\n",
      "  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      ")\n",
      "backbone.layer4.0.conv1 Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "backbone.layer4.0.bn1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer4.0.conv2 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "backbone.layer4.0.bn2 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer4.0.relu ReLU(inplace=True)\n",
      "backbone.layer4.0.downsample Sequential(\n",
      "  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "backbone.layer4.0.downsample.0 Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "backbone.layer4.0.downsample.1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer4.0.drop_path Identity()\n",
      "backbone.layer4.1 BasicBlock(\n",
      "  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (drop_path): Identity()\n",
      ")\n",
      "backbone.layer4.1.conv1 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "backbone.layer4.1.bn1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer4.1.conv2 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "backbone.layer4.1.bn2 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "backbone.layer4.1.relu ReLU(inplace=True)\n",
      "backbone.layer4.1.drop_path Identity()\n",
      "20\n",
      "Automatically choose the last norm layer \"backbone.layer4.1.bn2\" as the target layer.\n"
     ]
    }
   ],
   "source": [
    "!python tools/visualization/vis_cam.py \\\n",
    "    data/YoriDataset_vgg/train/MCI/100x-103.png \\\n",
    "    configs/resnet/resnet18_8xb16_cifar10_alzheimer_axial_view.py \\\n",
    "    work_dirs/alzheimer/axial/vgg16/latest1.pth \\\n",
    "    # --target-layers backbone.layer4.1 \\\n",
    "    --method GradCAM\n",
    "    # GradCAM++, XGradCAM, EigenCAM, EigenGradCAM, LayerCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9fee1-c40b-4d3a-a0b2-2ee1aea9facb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
